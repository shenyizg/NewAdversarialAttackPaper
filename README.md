# Latest Adversarial Attack Papers
**update at 2026-01-25 10:36:50**

This index groups papers by model family and attack/defense focus.
Each category has both English and Simplified Chinese lists.
Entries are sorted by LLM classifier confidence (high to low).

## Taxonomy
- Model types: LLM/MLLM, General Generative Models, Traditional Deep Learning Models
- LLM/Generative categories: Base/Interpretation, Red Teaming/Jailbreak, Safety Alignment, Other
- Traditional categories: Digital Attack, Physical Attack, Adversarial Defense

## LLM / MLLM (Language Models)

- Base/Interpretation: [EN](llm-base.md) [中文](llm-base-cn.md)
- Red Teaming/Jailbreak: [EN](llm-red-teaming-jailbreak.md) [中文](llm-red-teaming-jailbreak-cn.md)
- Safety Alignment: [EN](llm-safety-alignment.md) [中文](llm-safety-alignment-cn.md)
- Other: [EN](llm-other.md) [中文](llm-other-cn.md)

## General Generative Models

- Base/Interpretation: [EN](generative-base.md) [中文](generative-base-cn.md)
- Red Teaming/Jailbreak: [EN](generative-red-teaming-jailbreak.md) [中文](generative-red-teaming-jailbreak-cn.md)
- Safety Alignment: [EN](generative-safety-alignment.md) [中文](generative-safety-alignment-cn.md)
- Other: [EN](generative-other.md) [中文](generative-other-cn.md)

## Traditional Deep Learning Models

- Digital Attack: [EN](traditional-digital-attack.md) [中文](traditional-digital-attack-cn.md)
- Physical Attack: [EN](traditional-physical-attack.md) [中文](traditional-physical-attack-cn.md)
- Adversarial Defense: [EN](traditional-adversarial-defense.md) [中文](traditional-adversarial-defense-cn.md)

